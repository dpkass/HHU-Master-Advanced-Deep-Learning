{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ea1998b",
   "metadata": {},
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3854f7b7",
   "metadata": {},
   "source": [
    "## Group \n",
    "- **ID**: <your group ID>\n",
    "\n",
    "- **Members**: \n",
    "    - <your name1>\n",
    "    - <your name2>\n",
    "    - <your name3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f91a77",
   "metadata": {},
   "source": [
    "## Hand-in\n",
    "- Please hand in this notebook with your code implementation via Ilias \n",
    "- Please make sure that there is exactly **one** submission per group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9912ed",
   "metadata": {},
   "source": [
    "## Task Description\n",
    "\n",
    "In this exercise, you will implement a custom Extended Long Short-Term Memory (xLSTM) model to predict the next tokens given an input sequence. The Model is described in the paper [xLSTM: Extended Long Short-Term Memory](https://arxiv.org/abs/2405.04517).\n",
    "\n",
    "You will work with the “Tiny Shakespeare” dataset, a character-level corpus of Shakespeare’s plays and sonnets, commonly used for next-character prediction. The dataset is available at [Github](https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt).\n",
    "\n",
    "You will implement a custom character‐level tokenizer and DataLoader, write your costum Model(with different classes) and train it, plot the Perplexity score and the loss curve and finally showcase input–output text samples from your trained xLSTM.\n",
    "\n",
    "** NEW **:\n",
    "We provide some of the mLSTM and sLSTM code, as illustrated in Figures 10 and 11 of the xLSTM paper. For this part, you only need to implement the mLSTMCell and sLSTMCell classes, the gray boxes shown in those figures, and integrate them with the rest of the code. You’re free to modify any part of the provided code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179cb37b",
   "metadata": {},
   "source": [
    "## Grading scheme\n",
    "Total: 5 points\n",
    "1. **Preparing the Tokenizer and Dataloader** (1 point)\n",
    "2. **Preparing the Model** (2.5 point)\n",
    "3. **Train the Model** (1 point)\n",
    "4. **Showcasing plots and few input & output examples** (0.5 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584ba859",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce1eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc3e99f",
   "metadata": {},
   "source": [
    "### **Preparing the Tokenizer and Dataloader** (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21572718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f8466d1",
   "metadata": {},
   "source": [
    "### **Preparing the Model** (2.5 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56439879",
   "metadata": {},
   "source": [
    "#### components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89838416",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockDiagonalProj(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads):\n",
    "        super(BlockDiagonalProj, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.out_head_size = input_dim // num_heads\n",
    "        self.weight = nn.Parameter(torch.empty(num_heads, self.out_head_size, input_dim // num_heads))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shape = x.shape\n",
    "        x = x.view(*shape[:-1], self.num_heads, -1)\n",
    "        x = torch.einsum(\"...hd,hod->...ho\", x, self.weight)\n",
    "        x = x.reshape(*shape[:-1], -1)\n",
    "        return x\n",
    "    \n",
    "class CasualConv1d(nn.Module):\n",
    "    def __init__(self, feature_dim, kernel_size, bias=True):\n",
    "        super(CasualConv1d, self).__init__()\n",
    "        self.pad = (kernel_size -1)\n",
    "        self.conv = nn.Conv1d(in_channels=feature_dim, out_channels=feature_dim, kernel_size=kernel_size, padding=self.pad, groups=feature_dim, bias=bias)\n",
    "    def forward(self, x):\n",
    "        y = x.transpose(2, 1)\n",
    "        y = self.conv(y)\n",
    "        return y[:, :, : -self.pad].transpose(2, 1)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b2eddd",
   "metadata": {},
   "source": [
    "#### mLSTM block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b08a4ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPLETE THIS CLASS ####\n",
    "class mLSTMCell(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(mLSTMCell, self).__init__()\n",
    "    def forward(self,):\n",
    "        pass\n",
    "#############################  \n",
    "\n",
    "class mLSTMLayer(nn.Module): \n",
    "    def __init__(self, embedding_dim, proj_blocksize, bias=False):\n",
    "        super(mLSTMLayer, self).__init__()\n",
    "        self.outer_embedding_dim = embedding_dim\n",
    "        self.inner_embedding_dim = 2 * embedding_dim\n",
    "        self.proj_blocksize = proj_blocksize\n",
    "        self.bias = bias\n",
    "        \n",
    "        self.proj_up = nn.Linear(in_features=self.outer_embedding_dim, \n",
    "                                 out_features= 2 * self.inner_embedding_dim, \n",
    "                                 bias=bias)\n",
    "        self.num_proj_heads = self.inner_embedding_dim // proj_blocksize\n",
    "        self.q_proj = BlockDiagonalProj(input_dim=self.inner_embedding_dim, num_heads=self.num_proj_heads)\n",
    "        self.k_proj = BlockDiagonalProj(input_dim=self.inner_embedding_dim, num_heads=self.num_proj_heads)\n",
    "        self.v_proj = BlockDiagonalProj(input_dim=self.inner_embedding_dim, num_heads=self.num_proj_heads)\n",
    "        \n",
    "        self.conv1d = CasualConv1d(feature_dim=self.inner_embedding_dim, kernel_size=4)\n",
    "        self.conv_swish = nn.SiLU()\n",
    "        \n",
    "        ############################     EDIT      ##################################\n",
    "        self.mlstm_cell = mLSTMCell()\n",
    "        ##############################################################\n",
    "        \n",
    "        self.ogate_swish = nn.SiLU()\n",
    "        self.learnable_skip_con = nn.Parameter(torch.ones(self.inner_embedding_dim, requires_grad=True))\n",
    "        self.proj_down = nn.Linear(in_features=self.inner_embedding_dim,\n",
    "                                 out_features=self.outer_embedding_dim, \n",
    "                                 bias=bias)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, S, _ = x.shape\n",
    "        x_ = F.layer_norm(x, normalized_shape=(self.outer_embedding_dim,))\n",
    "        x_inner = self.proj_up(x_)  \n",
    "        x_mlstm, z = torch.split(x_inner, split_size_or_sections=self.inner_embedding_dim, dim=-1)\n",
    "        x_mlstm_conv = self.conv1d(x_mlstm)\n",
    "        x_mlstm_conv_act = self.conv_swish(x_mlstm_conv)\n",
    "        \n",
    "        q = self.q_proj(x_mlstm_conv_act)\n",
    "        k = self.k_proj(x_mlstm_conv_act)\n",
    "        v = self.v_proj(x_mlstm)\n",
    "        \n",
    "        ##########################     EDIT      ####################################\n",
    "        mlstm_cell_state = self.mlstm_cell()\n",
    "        ##############################################################\n",
    "        \n",
    "        mlstm_cell_skip = mlstm_cell_state + (self.learnable_skip_con * x_mlstm_conv_act)\n",
    "        \n",
    "        h_state = mlstm_cell_skip * self.ogate_swish(z)\n",
    "        \n",
    "        y = self.proj_down(h_state) + x\n",
    "        \n",
    "        return y\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94243fd3",
   "metadata": {},
   "source": [
    "#### sLSTM block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e70c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPLETE THIS CLASS ####\n",
    "class sLSTMCell(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(sLSTMCell, self).__init__()\n",
    "    def forward(self,):\n",
    "        pass\n",
    "#############################  \n",
    "    \n",
    "class sLSTMLayer(nn.Module): \n",
    "    def __init__(self, embedding_dim, proj_blocksize, conv_block=True, bias=False):\n",
    "        super(sLSTMLayer, self).__init__()\n",
    "        self.inner_embedding_dim = embedding_dim\n",
    "        self.proj_blocksize = proj_blocksize\n",
    "        self.conv_block = conv_block\n",
    "        if conv_block:\n",
    "            self.conv1d = CasualConv1d(feature_dim=self.inner_embedding_dim, kernel_size=4)\n",
    "            self.conv_swish = nn.SiLU()\n",
    "        \n",
    "        self.i_proj = BlockDiagonalProj(input_dim=self.inner_embedding_dim, num_heads=4)\n",
    "        self.f_proj = BlockDiagonalProj(input_dim=self.inner_embedding_dim, num_heads=4)\n",
    "        self.z_proj = BlockDiagonalProj(input_dim=self.inner_embedding_dim, num_heads=4)\n",
    "        self.o_proj = BlockDiagonalProj(input_dim=self.inner_embedding_dim, num_heads=4)\n",
    "        \n",
    "        ##############################     EDIT      ################################\n",
    "        self.slstm_cell = sLSTMCell()\n",
    "        ##############################################################\n",
    "        \n",
    "        self.up_proj1 = nn.Linear(in_features=self.inner_embedding_dim, out_features= int((4/3)*self.inner_embedding_dim), bias=bias)\n",
    "        self.up_proj2 = nn.Linear(in_features=self.inner_embedding_dim, out_features= int((4/3)*self.inner_embedding_dim), bias=bias)\n",
    "        self.up_proj2_gelu = nn.GELU()\n",
    "        \n",
    "        self.down_proj = nn.Linear(in_features=int((4/3)*self.inner_embedding_dim), out_features=self.inner_embedding_dim, bias=bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, S, _ = x.shape\n",
    "        \n",
    "        x_ = F.layer_norm(x, normalized_shape=(self.inner_embedding_dim,))\n",
    "        \n",
    "        if self.conv_block:\n",
    "            x_conv = self.conv1d(x_)\n",
    "            x_conv_act = self.conv_swish(x_conv)\n",
    "        else:\n",
    "            x_conv_act = x_\n",
    "        i = self.i_proj(x_conv_act)\n",
    "        f = self.f_proj(x_conv_act)\n",
    "        z = self.z_proj(x_)\n",
    "        o = self.o_proj(x_)\n",
    "        \n",
    "        ###########################     EDIT      ###################################\n",
    "        y_ = self.slstm_cell()\n",
    "        ##############################################################\n",
    "        \n",
    "        B_, NH_, S_, DH_ = y_.shape\n",
    "        gn_in_1 = y_.transpose(1, 2)\n",
    "        gn_in_2 = gn_in_1.reshape(B_ * S_, NH_ * DH_)\n",
    "        gn_out = F.group_norm(gn_in_2, num_groups=NH_)\n",
    "        out = gn_out.view(B_, S_, NH_, DH_).transpose(1, 2)\n",
    "        out = out.transpose(1, 2).view(B, S, -1)\n",
    "        \n",
    "        skip_con = x + out\n",
    "        skip_con_layer_norm = F.layer_norm(skip_con, normalized_shape=(self.inner_embedding_dim,))\n",
    "        \n",
    "        up_proj1 = self.up_proj1(skip_con_layer_norm)\n",
    "        up_proj2 = self.up_proj2(skip_con_layer_norm)\n",
    "        up_proj2_act = self.up_proj2_gelu(up_proj2)\n",
    "        down_proj = self.down_proj(up_proj2_act * up_proj1)\n",
    "        y = down_proj + skip_con\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5d0482",
   "metadata": {},
   "source": [
    "### **Train the Model** (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160f7af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6077deee",
   "metadata": {},
   "source": [
    "### **Showcasing plots and few input & output examples** (0.5 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c5351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
