{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ea1998b",
   "metadata": {},
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3854f7b7",
   "metadata": {},
   "source": [
    "## Group\n",
    "- **ID**: 5\n",
    "\n",
    "- **Members**:\n",
    "    - Hasan Algafri\n",
    "    - Emre Dursunluer\n",
    "    - Taha El Amine Kassabi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f91a77",
   "metadata": {},
   "source": [
    "## Hand-in\n",
    "- Please hand in this notebook with your code implementation via Ilias \n",
    "- Please make sure that there is exactly **one** submission per group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9912ed",
   "metadata": {},
   "source": [
    "## Task Description\n",
    "\n",
    "In this exercise, you will implement a custom Extended Long Short-Term Memory (xLSTM) model to predict the next tokens given an input sequence. The Model is described in the paper [xLSTM: Extended Long Short-Term Memory](https://arxiv.org/abs/2405.04517).\n",
    "\n",
    "You will work with the “Tiny Shakespeare” dataset, a character-level corpus of Shakespeare’s plays and sonnets, commonly used for next-character prediction. The dataset is available at [Github](https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt).\n",
    "\n",
    "You will implement a custom character‐level tokenizer and DataLoader, write your costum Model(with different classes) and train it, plot the Perplexity score and the loss curve and finally showcase input–output text samples from your trained xLSTM.\n",
    "\n",
    "** NEW **:\n",
    "We provide some of the mLSTM and sLSTM code, as illustrated in Figures 10 and 11 of the xLSTM paper. For this part, you only need to implement the mLSTMCell and sLSTMCell classes, the gray boxes shown in those figures, and integrate them with the rest of the code. You’re free to modify any part of the provided code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179cb37b",
   "metadata": {},
   "source": [
    "## Grading scheme\n",
    "Total: 5 points\n",
    "1. **Preparing the Tokenizer and Dataloader** (1 point)\n",
    "2. **Preparing the Model** (2.5 point)\n",
    "3. **Train the Model** (1 point)\n",
    "4. **Showcasing plots and few input & output examples** (0.5 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584ba859",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "3ce1eb1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T10:02:07.577623Z",
     "start_time": "2025-06-15T10:02:05.820784Z"
    }
   },
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "os.makedirs(\"../models/\", exist_ok=True)\n",
    "os.makedirs(\"../data/\", exist_ok=True)"
   ],
   "id": "b6ae92b13ae952e7"
  },
  {
   "cell_type": "markdown",
   "id": "fcc3e99f",
   "metadata": {},
   "source": [
    "### **Preparing the Tokenizer and Dataloader** (1 point)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T10:02:07.861939Z",
     "start_time": "2025-06-15T10:02:07.713087Z"
    }
   },
   "cell_type": "code",
   "source": "!wget -nc -O ../data/tinyshakespeare.txt https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt",
   "id": "ea0e58ed90c6a8f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘../data/tinyshakespeare.txt’ already there; not retrieving.\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "21572718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T10:02:07.882708Z",
     "start_time": "2025-06-15T10:02:07.874377Z"
    }
   },
   "source": [
    "class CharTokenizer:\n",
    "    '''\n",
    "    Simple character level tokenizer; maps each unique character to an integer index.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, text):\n",
    "        chars = sorted(set(text))\n",
    "        self.vocab_size = len(chars)\n",
    "        self.char_to_tok = {ch: i for i, ch in enumerate(chars)}\n",
    "        self.tok_to_char = {i: ch for ch, i in self.char_to_tok.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.vocab_size\n",
    "\n",
    "    def __call__(self, text):\n",
    "        return self.encode(text)\n",
    "\n",
    "    def encode(self, text):\n",
    "        return [self.char_to_tok[ch] for ch in text]\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        return [self.tok_to_char[tok] for tok in tokens]\n",
    "\n",
    "\n",
    "class CharTokenizedText(Dataset):\n",
    "    def __init__(self, text, tokenizer, seq_len=128):\n",
    "        self.text = text\n",
    "        self.seq_len = seq_len\n",
    "        self.data = torch.tensor(tokenizer(text), dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx: idx + self.seq_len]\n",
    "        y = self.data[idx + 1: idx + self.seq_len + 1]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def load_data(train_proportion=0.8, batch_size=128, seq_len=128):\n",
    "    with open(\"../data/tinyshakespeare.txt\", \"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    tokenizer = CharTokenizer(text)\n",
    "\n",
    "    ds = lambda txt: CharTokenizedText(txt, tokenizer, seq_len)\n",
    "    dl = lambda ds, shuffle=False: DataLoader(ds, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    train_chars = int(len(text) * train_proportion)\n",
    "    train_text, val_text = text[:train_chars], text[train_chars:]\n",
    "    train_ds, val_ds = ds(train_text), ds(val_text)\n",
    "    return dl(train_ds, True), dl(val_ds), tokenizer"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "5f8466d1",
   "metadata": {},
   "source": [
    "### **Preparing the Model** (2.5 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56439879",
   "metadata": {},
   "source": [
    "#### components"
   ]
  },
  {
   "cell_type": "code",
   "id": "89838416",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T10:02:07.912934Z",
     "start_time": "2025-06-15T10:02:07.904555Z"
    }
   },
   "source": [
    "class BlockDiagonalProj(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads):\n",
    "        super(BlockDiagonalProj, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.out_head_size = input_dim // num_heads\n",
    "        self.weight = nn.Parameter(torch.empty(num_heads, self.out_head_size, input_dim // num_heads))\n",
    "        nn.init.normal_(\n",
    "            self.weight.data,\n",
    "            mean=0.0,\n",
    "            std=(2.0 / 5.0 / self.weight.shape[-1]) ** .5\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shape = x.shape\n",
    "        x = x.view(*shape[:-1], self.num_heads, -1)\n",
    "        x = torch.einsum(\"...hd,hod->...ho\", x, self.weight)\n",
    "        x = x.reshape(*shape[:-1], -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CasualConv1d(nn.Module):\n",
    "    def __init__(self, feature_dim, kernel_size, bias=True):\n",
    "        super(CasualConv1d, self).__init__()\n",
    "        self.pad = (kernel_size - 1)\n",
    "        self.conv = nn.Conv1d(in_channels=feature_dim, out_channels=feature_dim, kernel_size=kernel_size, padding=self.pad, groups=feature_dim, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x.transpose(2, 1)\n",
    "        y = self.conv(y)\n",
    "        return y[:, :, : -self.pad].transpose(2, 1)\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "50b2eddd",
   "metadata": {},
   "source": [
    "#### mLSTM block"
   ]
  },
  {
   "cell_type": "code",
   "id": "b08a4ef7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T10:02:07.939691Z",
     "start_time": "2025-06-15T10:02:07.923352Z"
    }
   },
   "source": [
    "### COMPLETE THIS CLASS ####\n",
    "class mLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(mLSTMCell, self).__init__()\n",
    "        self.i = nn.Linear(input_dim, input_dim)\n",
    "        self.f = nn.Linear(input_dim, input_dim)\n",
    "        self.o = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "        B, S, D = q.shape\n",
    "        h = torch.empty_like(q)\n",
    "        C = torch.zeros(B, D, D, device=q.device, dtype=q.dtype)\n",
    "        n = torch.zeros(B, D, device=q.device, dtype=q.dtype)\n",
    "        m_prev = torch.zeros_like(n)\n",
    "\n",
    "        i = self.i(k)\n",
    "        f = self.f(k)\n",
    "        o = self.o(k).sigmoid()\n",
    "\n",
    "        for t in range(S):\n",
    "            q_t = q[:, t, :]  # (B, D)\n",
    "            k_t = k[:, t, :]\n",
    "            v_t = v[:, t, :]\n",
    "\n",
    "            i_t = i[:, t, :]\n",
    "            f_t = f[:, t, :]\n",
    "            o_t = o[:, t, :]\n",
    "\n",
    "            m_t = torch.maximum(f_t + m_prev, i_t)\n",
    "\n",
    "            i_t = (i_t - m_t).exp()\n",
    "            f_t = (f_t + m_prev - m_t).exp()\n",
    "            n = f_t * n + i_t * k_t\n",
    "            C = f_t.unsqueeze(-1) * C + i_t.unsqueeze(-1) * (v_t.unsqueeze(-1) @ k_t.unsqueeze(-2))\n",
    "\n",
    "            h_t_raw = C @ q_t.unsqueeze(-1) / (n.unsqueeze(-2) @ q_t.unsqueeze(-1)).clamp(min=1)\n",
    "            h[:, t, :] = o_t * h_t_raw.squeeze()\n",
    "\n",
    "            m_prev = m_t\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "#############################\n",
    "\n",
    "class mLSTMLayer(nn.Module):\n",
    "    def __init__(self, embedding_dim, proj_blocksize, bias=False):\n",
    "        super(mLSTMLayer, self).__init__()\n",
    "        self.outer_embedding_dim = embedding_dim\n",
    "        self.inner_embedding_dim = 2 * embedding_dim\n",
    "        self.proj_blocksize = proj_blocksize\n",
    "        self.bias = bias\n",
    "\n",
    "        self.proj_up = nn.Linear(in_features=self.outer_embedding_dim,\n",
    "                                 out_features=2 * self.inner_embedding_dim,\n",
    "                                 bias=bias)\n",
    "        self.num_proj_heads = self.inner_embedding_dim // proj_blocksize\n",
    "        self.q_proj = BlockDiagonalProj(input_dim=self.inner_embedding_dim, num_heads=self.num_proj_heads)\n",
    "        self.k_proj = BlockDiagonalProj(input_dim=self.inner_embedding_dim, num_heads=self.num_proj_heads)\n",
    "        self.v_proj = BlockDiagonalProj(input_dim=self.inner_embedding_dim, num_heads=self.num_proj_heads)\n",
    "\n",
    "        self.conv1d = CasualConv1d(feature_dim=self.inner_embedding_dim, kernel_size=4)\n",
    "        self.conv_swish = nn.SiLU()\n",
    "\n",
    "        ############################     EDIT      ##################################\n",
    "        self.mlstm_cell = mLSTMCell(self.inner_embedding_dim)\n",
    "        ##############################################################\n",
    "\n",
    "        self.ogate_swish = nn.SiLU()\n",
    "        self.learnable_skip_con = nn.Parameter(torch.ones(self.inner_embedding_dim, requires_grad=True))\n",
    "        self.proj_down = nn.Linear(in_features=self.inner_embedding_dim,\n",
    "                                   out_features=self.outer_embedding_dim,\n",
    "                                   bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, S, _ = x.shape\n",
    "        x_ = F.layer_norm(x, normalized_shape=(self.outer_embedding_dim,))\n",
    "        x_inner = self.proj_up(x_)\n",
    "        x_mlstm, z = torch.split(x_inner, split_size_or_sections=self.inner_embedding_dim, dim=-1)\n",
    "        x_mlstm_conv = self.conv1d(x_mlstm)\n",
    "        x_mlstm_conv_act = self.conv_swish(x_mlstm_conv)\n",
    "\n",
    "        q = self.q_proj(x_mlstm_conv_act)\n",
    "        k = self.k_proj(x_mlstm_conv_act)\n",
    "        v = self.v_proj(x_mlstm)\n",
    "\n",
    "        ##########################     EDIT      ####################################\n",
    "        mlstm_cell_state = self.mlstm_cell(q, k, v)\n",
    "        ##############################################################\n",
    "\n",
    "        mlstm_cell_skip = mlstm_cell_state + (self.learnable_skip_con * x_mlstm_conv_act)\n",
    "\n",
    "        h_state = mlstm_cell_skip * self.ogate_swish(z)\n",
    "\n",
    "        y = self.proj_down(h_state) + x\n",
    "\n",
    "        return y\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "94243fd3",
   "metadata": {},
   "source": [
    "#### sLSTM block"
   ]
  },
  {
   "cell_type": "code",
   "id": "2e70c0d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T10:02:07.967907Z",
     "start_time": "2025-06-15T10:02:07.950802Z"
    }
   },
   "source": [
    "### COMPLETE THIS CLASS ####\n",
    "class sLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads):\n",
    "        super(sLSTMCell, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = input_dim // num_heads\n",
    "\n",
    "        self.r_z = nn.Linear(input_dim, input_dim, bias=False)\n",
    "        self.r_i = nn.Linear(input_dim, input_dim, bias=False)\n",
    "        self.r_f = nn.Linear(input_dim, input_dim, bias=False)\n",
    "        self.r_o = nn.Linear(input_dim, input_dim, bias=False)\n",
    "\n",
    "    def forward(self, i_logits, f_logits, z_logits, o_logits):\n",
    "        B, S, D = i_logits.shape\n",
    "        NH, DH = self.num_heads, self.head_dim\n",
    "\n",
    "        i_logits = i_logits.view(B, NH, S, DH)\n",
    "        f_logits = f_logits.view(B, NH, S, DH)\n",
    "        z_logits = z_logits.view(B, NH, S, DH)\n",
    "        o_logits = o_logits.view(B, NH, S, DH)\n",
    "\n",
    "        c = torch.zeros(B, NH, DH, device=i_logits.device, dtype=i_logits.dtype)\n",
    "        n = torch.zeros_like(c)\n",
    "        m_prev = torch.zeros_like(c)\n",
    "        h = torch.zeros_like(i_logits)\n",
    "        h_t_prev = h[:, :, 0, :].reshape(B, -1)\n",
    "\n",
    "        for t in range(S):\n",
    "            r_z_t = self.r_z(h_t_prev).view(B, NH, DH)\n",
    "            r_i_t = self.r_i(h_t_prev).view(B, NH, DH)\n",
    "            r_f_t = self.r_f(h_t_prev).view(B, NH, DH)\n",
    "            r_o_t = self.r_o(h_t_prev).view(B, NH, DH)\n",
    "\n",
    "            z_t = (z_logits[:, :, t, :] + r_z_t).sigmoid()\n",
    "            o_t = (o_logits[:, :, t, :] + r_o_t).tanh()\n",
    "\n",
    "            i_t = i_logits[:, :, t, :] + r_i_t\n",
    "            f_t = f_logits[:, :, t, :] + r_f_t\n",
    "            m_t = torch.maximum(f_t + m_prev, i_t)\n",
    "\n",
    "            i_t = (i_t - m_t).exp()\n",
    "            f_t = (f_t + m_prev - m_t).exp()\n",
    "\n",
    "            c = f_t * c + i_t * z_t\n",
    "            n = f_t * n + i_t\n",
    "\n",
    "            h_t_raw = c / n\n",
    "            h[:, :, t, :] = o_t * h_t_raw\n",
    "            h_t_prev = h[:, :, t, :].reshape(B, -1)\n",
    "\n",
    "            m_prev = m_t\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "#############################\n",
    "\n",
    "class sLSTMLayer(nn.Module):\n",
    "    def __init__(self, embedding_dim, proj_blocksize, conv_block=True, bias=False):\n",
    "        super(sLSTMLayer, self).__init__()\n",
    "        self.inner_embedding_dim = embedding_dim\n",
    "        self.proj_blocksize = proj_blocksize\n",
    "        self.conv_block = conv_block\n",
    "        if conv_block:\n",
    "            self.conv1d = CasualConv1d(feature_dim=self.inner_embedding_dim, kernel_size=4)\n",
    "            self.conv_swish = nn.SiLU()\n",
    "\n",
    "        self.i_proj = BlockDiagonalProj(input_dim=self.inner_embedding_dim, num_heads=4)\n",
    "        self.f_proj = BlockDiagonalProj(input_dim=self.inner_embedding_dim, num_heads=4)\n",
    "        self.z_proj = BlockDiagonalProj(input_dim=self.inner_embedding_dim, num_heads=4)\n",
    "        self.o_proj = BlockDiagonalProj(input_dim=self.inner_embedding_dim, num_heads=4)\n",
    "\n",
    "        ##############################     EDIT      ################################\n",
    "        self.slstm_cell = sLSTMCell(self.inner_embedding_dim, num_heads=4)\n",
    "        ##############################################################\n",
    "\n",
    "        self.up_proj1 = nn.Linear(in_features=self.inner_embedding_dim, out_features=int((4 / 3) * self.inner_embedding_dim), bias=bias)\n",
    "        self.up_proj2 = nn.Linear(in_features=self.inner_embedding_dim, out_features=int((4 / 3) * self.inner_embedding_dim), bias=bias)\n",
    "        self.up_proj2_gelu = nn.GELU()\n",
    "\n",
    "        self.down_proj = nn.Linear(in_features=int((4 / 3) * self.inner_embedding_dim), out_features=self.inner_embedding_dim, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, S, _ = x.shape\n",
    "\n",
    "        x_ = F.layer_norm(x, normalized_shape=(self.inner_embedding_dim,))\n",
    "\n",
    "        if self.conv_block:\n",
    "            x_conv = self.conv1d(x_)\n",
    "            x_conv_act = self.conv_swish(x_conv)\n",
    "        else:\n",
    "            x_conv_act = x_\n",
    "        i = self.i_proj(x_conv_act)\n",
    "        f = self.f_proj(x_conv_act)\n",
    "        z = self.z_proj(x_)\n",
    "        o = self.o_proj(x_)\n",
    "\n",
    "        ###########################     EDIT      ###################################\n",
    "        y_ = self.slstm_cell(i, f, z, o)\n",
    "        ##############################################################\n",
    "\n",
    "        B_, NH_, S_, DH_ = y_.shape\n",
    "        gn_in_1 = y_.transpose(1, 2)\n",
    "        gn_in_2 = gn_in_1.reshape(B_ * S_, NH_ * DH_)\n",
    "        gn_out = F.group_norm(gn_in_2, num_groups=NH_)\n",
    "        out = gn_out.view(B_, S_, NH_, DH_).transpose(1, 2)\n",
    "        out = out.transpose(1, 2).view(B, S, -1)\n",
    "\n",
    "        skip_con = x + out\n",
    "        skip_con_layer_norm = F.layer_norm(skip_con, normalized_shape=(self.inner_embedding_dim,))\n",
    "\n",
    "        up_proj1 = self.up_proj1(skip_con_layer_norm)\n",
    "        up_proj2 = self.up_proj2(skip_con_layer_norm)\n",
    "        up_proj2_act = self.up_proj2_gelu(up_proj2)\n",
    "        down_proj = self.down_proj(up_proj2_act * up_proj1)\n",
    "        y = down_proj + skip_con\n",
    "        return y"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T10:02:07.986700Z",
     "start_time": "2025-06-15T10:02:07.981759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class xLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, layers=(3, 1), embedding_dim=128, proj_blocksize=64):\n",
    "        assert sum(layers) > 0, \"Minimum 1 layer.\"\n",
    "        super(xLSTM, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        m_layers, s_layers = layers\n",
    "        self.layers = nn.Sequential(\n",
    "            *[mLSTMLayer(embedding_dim, proj_blocksize) for _ in range(m_layers)],\n",
    "            *[sLSTMLayer(embedding_dim, proj_blocksize) for _ in range(s_layers)]\n",
    "        )\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_normal_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.Parameter):\n",
    "            nn.init.normal_(module, mean=0, std=0.02)\n",
    "        elif isinstance(module, BlockDiagonalProj):\n",
    "            self._init_weights(module.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.layers(x)\n",
    "        x = self.layer_norm(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "    def generate(self, tokenizer, prompt, max_length=200):\n",
    "        x = tokenizer.encode(prompt).unsqueeze(0)\n",
    "        for _ in range(max_length):\n",
    "            logits = self(x)\n",
    "            x = torch.cat([x, logits.argmax(dim=-1, keepdim=True)], dim=1)\n",
    "        return tokenizer.decode(x.squeeze(0))"
   ],
   "id": "a3ede0dc2b970c5d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "5a5d0482",
   "metadata": {},
   "source": [
    "### **Train the Model** (1 point)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T10:02:09.176625Z",
     "start_time": "2025-06-15T10:02:08.000090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Configuration:\n",
    "    def __init__(self):\n",
    "        self.device = device\n",
    "\n",
    "        self.num_epochs = 5\n",
    "        self.lr = 1e-4\n",
    "\n",
    "        train_proportion = 0.8\n",
    "        batch_size = 64\n",
    "        seq_len = 128\n",
    "\n",
    "        self.train_dl, self.val_dl, self.tokenizer = load_data(train_proportion, batch_size, seq_len)\n",
    "        self.model = xLSTM(len(self.tokenizer))\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "\n",
    "config = Configuration()"
   ],
   "id": "3b1e5edb5aa962a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T10:02:09.196218Z",
     "start_time": "2025-06-15T10:02:09.185121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_one_epoch(config):\n",
    "    model = config.model\n",
    "    device = config.device\n",
    "    train_dl = config.train_dl\n",
    "    criterion = config.criterion\n",
    "    optimizer = config.optimizer\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for X, y in tqdm(train_dl, desc=\"Train\", leave=False):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits.view(-1, logits.shape[-1]), y.view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss\n",
    "\n",
    "    total_loss /= len(train_dl)\n",
    "    return total_loss.item(), total_loss.exp().item()\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def validate(config):\n",
    "    model = config.model\n",
    "    device = config.device\n",
    "    val_dl = config.val_dl\n",
    "    criterion = config.criterion\n",
    "\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    for X, y in tqdm(val_dl, desc=\"Validate\", leave=False):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        logits = model(X)\n",
    "        total_loss += criterion(logits.view(-1, logits.shape[-1]), y.view(-1))\n",
    "\n",
    "    total_loss /= len(val_dl)\n",
    "    return total_loss.item(), total_loss.exp().item()\n",
    "\n",
    "\n",
    "def train(config):\n",
    "    config.model.to(config.device)\n",
    "    log = defaultdict(list)\n",
    "    for epoch in trange(config.num_epochs, desc=\"Epoch\"):\n",
    "        train_loss, train_ppl = train_one_epoch(config)\n",
    "        val_loss, val_ppl = validate(config)\n",
    "\n",
    "        log[\"train_loss\"].append(train_loss)\n",
    "        log[\"train_ppl\"].append(train_ppl)\n",
    "        log[\"val_loss\"].append(val_loss)\n",
    "        log[\"val_ppl\"].append(val_ppl)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f}, Train PPL: {train_ppl:.4f}, Val Loss: {val_loss:.4f}, Val PPL: {val_ppl:.4f}\")\n",
    "\n",
    "        if val_loss < min(log[\"val_loss\"]):\n",
    "            torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": config.model.state_dict(),\n",
    "                \"optimizer_state_dict\": config.optimizer.state_dict(),\n",
    "                \"loss\": val_loss,\n",
    "            }, \"../models/ex06_xlstm_min_val_ppl.pth\")\n",
    "\n",
    "    return log"
   ],
   "id": "b8814b1f47b6d1d9",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T10:02:09.215357Z",
     "start_time": "2025-06-15T10:02:09.210696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Vocabulary size: {len(config.tokenizer)}\")\n",
    "print(f\"Train dataset size: {len(config.train_dl.dataset)}\")\n",
    "print(f\"Validation dataset size: {len(config.val_dl.dataset)}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in config.model.parameters() if p.requires_grad):,}\")"
   ],
   "id": "ab457e124f059907",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 65\n",
      "Train dataset size: 892187\n",
      "Validation dataset size: 222951\n",
      "Model parameters: 1,203,905\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T10:06:48.250478Z",
     "start_time": "2025-06-15T10:02:09.258850Z"
    }
   },
   "cell_type": "code",
   "source": "log = train(config)",
   "id": "6e7b4eb4b24eb5a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e170240d2f5f4d2cbef9aea7fec90d4e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Train:   0%|          | 0/13941 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b139e50388846518372cef4b9568fd7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6077deee",
   "metadata": {},
   "source": [
    "### **Showcasing plots and few input & output examples** (0.5 point)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import matplotlib.pyplot as plt",
   "id": "5373bdec270071a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(log[\"train_loss\"], label=\"Train Loss\", marker=\"o\")\n",
    "plt.plot(log[\"val_loss\"], label=\"Validation Loss\", marker=\"s\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(log[\"train_ppl\"], label=\"Train Perplexity\", marker=\"o\")\n",
    "plt.plot(log[\"val_ppl\"], label=\"Validation Perplexity\", marker=\"s\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.title(\"Training and Validation Perplexity\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "bbd14d0e89de4b07"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prompts = [\n",
    "    \"ROMEO:\",\n",
    "    \"To be \",\n",
    "    \"JULIET:\",\n",
    "    \"O Romeo\",\n",
    "]\n",
    "\n",
    "fmt = f\"\"\"Prompt: '{{}}'\n",
    "{\"-\" * 40}\n",
    "{{}}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for prompt in prompts:\n",
    "    generated = config.model.generate(config.tokenizer, prompt=prompt)\n",
    "    print(fmt.format(prompt, generated))"
   ],
   "id": "d99e9bb14af78e68"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
